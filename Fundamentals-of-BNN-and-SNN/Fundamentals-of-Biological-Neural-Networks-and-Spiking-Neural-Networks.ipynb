{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5ac8e6",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3bbfa0; font-size:1.7em;\">*Lab Grown Human Brain Network:*</span><br> <span style=\"color:lightgray; font-size:1.2em;\">*As If a Dystopian A.I.-Governed Hellscape Wasn't Enough*</span>\n",
    "\n",
    "<img src=\"https://media.tenor.com/c67EEseOkQsAAAAd/matrix-battery.gif\" width=\"800\">\n",
    "\n",
    "<div style=\"position: relative; width: 580px;\">\n",
    "    <img src=\"./asset/img/glowwhite.png\" style=\"position: absolute; bottom: 210px; right: 0px; width: 120px;\">\n",
    "</div>\n",
    "    \n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76770e2a",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3bbfa0; font-size:1.2em;\">*1. The Leading Company \"Cortical Labs\":*</span>\n",
    "\n",
    "| | |\n",
    "|:-------------------------:|:-------------------------:|\n",
    "|<img width=\"500\" src=\"asset/img/demo7.gif\">|<img width=\"500\" src=\"asset/img/demo8.gif\">|\n",
    "<div style=\"position: relative; width: 50px;\">\n",
    "    <img src=\"./asset/img/cl.png\" style=\"position: absolute; bottom: 250px; right: 870px; width: 120px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d0bf1",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "### <span style=\"color:#3bbfa0; font-size:1.2em;\">*2. Cortical Lab's Work*</span><br> <span style=\"color:lightgray; font-size:1em;\">*Lab Grown Human Brain Plays Video Game*</span>\n",
    "\n",
    "___\n",
    "\n",
    "- Kagan, B. J., Kitchen, A. C., Tran, N. T., Habibollahi, F., Khajehnejad, M., Parker, B. J., Bhat, A., Rollo, B., Razi, A., & Friston, K. J. (2022). In vitro neurons learn and exhibit sentience when embodied in a simulated game-world. In Neuron (Vol. 110, Issue 23, pp. 3952-3969.e8). Elsevier BV. https://doi.org/10.1016/j.neuron.2022.09.001\n",
    "\n",
    "\n",
    "| | |\n",
    "|:-------------------------:|:-------------------------:|\n",
    "|<img width=\"400\" src=\"asset/img/pong.png\">|<img width=\"600\" src=\"asset/img/pong.gif\">|\n",
    "\n",
    "\n",
    "\n",
    "In this experiment, the reward for the biological neural networks (BNNs) was the predictable stimulation they received when they performed the desired action, which was successfully intercepting the ball in the game of \"Pong\". This predictable stimulation was considered as positive feedback or a reward, which encouraged the BNNs to repeat the successful action. Conversely, when the BNNs failed to intercept the ball, they received unpredictable stimulation, which was considered as negative feedback or a penalty. This system of rewards and penalties was used to train the BNNs to improve their performance in the game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8ae76",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "\n",
    "### <span style=\"color:#3bbfa0; font-size:1.2em;\">*3. How Does The Reward Work?*</span><br><span style=\"color:lightgray; font-size:1em;\">*Predictability Modulates Human Brain Response to Reward*</span>\n",
    "___\n",
    "\n",
    "- Berns, G. S., McClure, S. M., Pagnoni, G., & Montague, P. R. (2001). Predictability Modulates Human Brain Response to Reward. In The Journal of Neuroscience (Vol. 21, Issue 8, pp. 2793â€“2798). Society for Neuroscience. https://doi.org/10.1523/jneurosci.21-08-02793.2001\n",
    "\n",
    "<img src=\"asset/img/rwr.png\" width=\"800\">\n",
    "\n",
    "<div style=\"position: relative; width: 300px;\">\n",
    "    <img src=\"https://cdn.freebiesupply.com/logos/large/2x/emory-university-logo-png-transparent.png\" style=\"position: absolute; bottom: 320px; right: 0px; width: 170px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c80229d",
   "metadata": {},
   "source": [
    "Investigates how the predictability of a sequence of pleasurable stimuli affects the activity in human reward regions. The study used functional magnetic resonance imaging (fMRI) to monitor the brain activity of subjects who were given two mildly pleasurable stimuli, fruit juice and water, in either a predictable or unpredictable sequence.\n",
    "\n",
    "Key findings from the study include:\n",
    "\n",
    "1. The activity in the reward regions of the brain, specifically the nucleus accumbens and medial orbitofrontal cortex, was greatest when the stimuli (fruit juice and water) were delivered unpredictably.\n",
    "\n",
    "2. The subjects' stated preference for either juice or water did not directly correlate with activity in the reward regions. Instead, it was correlated with activity in the sensorimotor cortex.\n",
    "\n",
    "3. The study suggests that predictability modulates the response of human reward regions, and subjective preference can be dissociated from this response. \n",
    "\n",
    "       The researchers did two things: they looked at the brain activity of the subjects using fMRI scans, and \n",
    "       they asked the subjects which they liked better - the juice or the water.\n",
    "\n",
    "       They found that what the subjects said they preferred (juice or water) didn't match up with the activity \n",
    "       in the reward parts of their brains. Instead, their stated preferences were linked to activity in the \n",
    "       sensorimotor cortex, a part of the brain involved in processing sensory information and controlling movement.\n",
    "\n",
    "       This means that what people say they like doesn't always match up with what their brain's reward system \n",
    "       responds to. In other words, our conscious preferences can be different from our brain's automatic responses.\n",
    "\n",
    "\n",
    "The authors also discuss the implications of their findings in the context of the pursuit of natural rewards such as food, drink, and sex, and how these rewards affect human behavior. They suggest that the predictability of a sequence of pleasurable stimuli may recruit reward-related neural structures in a manner detectable with fMRI.\n",
    "\n",
    "<img src=\"asset/img/rwrP.png\" width=\"500\">\n",
    "\n",
    "<div style=\"position: relative; width: 200px;\">\n",
    "    <img src=\"asset/img/brain.png\" style=\"position: absolute; bottom: 120px; right: 0px; width: 150px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ee46c",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "\n",
    "### <span style=\"color:#3bbfa0; font-size:1.2em;\">*4. Why... ?*</span><br><br><span style=\"color:lightgray; font-size:1em;\">*GPT-4 Seems Like it is Working Fine*</span>\n",
    "\n",
    "\n",
    "<img width=\"850\" src=\"asset/img/demo9.gif\">\n",
    "<img width=\"850\" src=\"asset/img/demo10.gif\">\n",
    "\n",
    "<div style=\"position: relative; width: 500px;\">\n",
    "    <p style=\"color:#3bbfa0; font-size:2.4em; position: absolute; bottom: 520px; right: 0px; width: 400px;\">Multilayer Perceptron</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"position: relative; width: 500px;\">\n",
    "    <p style=\"color:#3bbfa0; font-size:2.4em; position: absolute; bottom: 20px; right: 0px; width: 400px;\">Spiking Neural Network</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399db6ee",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "| | |\n",
    "|:-------------------------:|:-------------------------:|\n",
    "|<img width=\"600\" src=\"asset/img/demo9.gif\">|<img width=\"600\" src=\"asset/img/demo10.gif\">|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972185b6",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br>\n",
    "\n",
    "### <span style=\"color:#3bbfa0; font-size:1.2em;\">*5. What are Spiking Neural Networks?*</span><br> <span style=\"color:lightgray; font-size:1em;\">*How Do They Relate to Biological Neural Networks?*</span>\n",
    "\n",
    "___\n",
    "\n",
    "-  Li, M., Ruan, H., Qi, Y., Guo, T., Wang, P., & Pan, G. (2019). Odor Recognition with a Spiking Neural Network for Bioelectronic Nose. In Sensors (Vol. 19, Issue 5, p. 993). MDPI AG. https://doi.org/10.3390/s19050993\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a0d91",
   "metadata": {},
   "source": [
    "<img width=\"600\" src=\"asset/img/SNN.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58773871",
   "metadata": {},
   "source": [
    "Here are the key points from the article \"Odor Recognition with a Spiking Neural Network for Bioelectronic Nose\":\n",
    "\n",
    "1. The study proposes a method for odor recognition using Spiking Neural Networks (SNNs) to decode spike trains recorded by an implanted electrode array in the olfactory bulb of rats.\n",
    "\n",
    "2. The authors introduce a new SNN learning method with a voltage-based regulation strategy to address the overfitting problem.\n",
    "\n",
    "3. Experiments show that the SNN-based approach outperforms other methods, achieving state-of-the-art performance. With the proposed voltage regulation strategy, it achieves about a 15% improvement compared to a classical SNN model.\n",
    "\n",
    "4. The SNN-based approach is compared with bin-based methods, demonstrating the effectiveness of using precise timing information. The SNN-VR (voltage regulation) approach shows better generalization ability, especially with small training sets.\n",
    "\n",
    "5. The study concludes that the SNN-VR approach is more feasible and effective in neural signal-based odor recognition tasks, providing a promising option for the development of bioelectronic noses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0610ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikegen\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "# from snntorch import spikegen, snn, utils\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Training Parameters\n",
    "batch_size = 128\n",
    "data_path = '/data/mnist'\n",
    "num_classes = 10  # MNIST has 10 output classes\n",
    "num_steps = 100 # Temporal Dynamics\n",
    "beta = 0.95\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,), (1,))\n",
    "])\n",
    "\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate through minibatches\n",
    "data = iter(train_loader)\n",
    "data_it, targets_it = next(data)\n",
    "\n",
    "# Spiking Data\n",
    "spike_data = spikegen.rate(data_it, num_steps=num_steps)\n",
    "\n",
    "# Network Architecture\n",
    "num_inputs = 28*28\n",
    "num_hidden = 1000\n",
    "num_outputs = 10\n",
    "\n",
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        # Record the final layer\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "net = Net().to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "\n",
    "num_epochs = 1\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "dtype = torch.float  # Define dtype\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        spk_rec, mem_rec = net(data.view(data.shape[0], -1))\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = torch.zeros((1), dtype=torch.float, device=device)\n",
    "        for step in range(num_steps):\n",
    "            loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Test set\n",
    "        with torch.no_grad():\n",
    "            net.eval()  \n",
    "            test_data, test_targets = next(iter(test_loader))\n",
    "            test_data = test_data.to(device)\n",
    "            test_targets = test_targets.to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            test_spk, test_mem = net(test_data.view(test_data.shape[0], -1))\n",
    "\n",
    "            # Test set loss\n",
    "            test_loss = torch.zeros((1), dtype=torch.float, device=device)\n",
    "\n",
    "            for step in range(num_steps):\n",
    "                test_loss += loss(test_mem[step], test_targets)\n",
    "\n",
    "            test_loss_hist.append(test_loss.item())\n",
    "\n",
    "            # Print test loss\n",
    "            if counter % 50 == 0:\n",
    "                print(\"Test loss: \", float(test_loss))\n",
    "\n",
    "            counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaca995",
   "metadata": {},
   "source": [
    "<img width=\"200\" src=\"asset/img/output.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3a644",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3bbfa0; font-size:1.2em;\">*5.1 Slayer*</span>\n",
    "___\n",
    "\n",
    "https://github.com/bamsumit/slayerPytorch\n",
    "\n",
    "<img width=\"500\" src=\"https://tinyurl.com/39jd4uk3\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa248a4a",
   "metadata": {},
   "source": [
    "### <span style=\"color:#3bbfa0; font-size:1.2em;\">*5.2 1000 FPS SSN*</span>\n",
    "___\n",
    "\n",
    "| | |\n",
    "|:-------------------------:|:-------------------------:|\n",
    "|<img width=\"400\" src=\"./asset/img/dvs.gif\"><img width=\"400\" src=\"./asset/img/trex.gif\">|<img width=\"300\" src=\"./asset/img/1000fps.png\">|\n",
    "\n",
    "- Zhang, C., Kang, L., Yang, X., Guo, G., Feng, P., Yu, S., & Liu, L. (2022). A 1000 fps Spiking Neural Network Tracking Algorithm for On-Chip Processing of Dynamic Vision Sensor Data. In 2022 IEEE International Conference on Integrated Circuits, Technologies and Applications (ICTA). 2022 IEEE International Conference on Integrated Circuits, Technologies and Applications (ICTA). IEEE. https://doi.org/10.1109/icta56932.2022.9962968\n",
    "\n",
    "Overview:\n",
    "\n",
    "1. The paper is about using Spiking Neural Network (SNN), to process data from a specific type of camera called a Dynamic Vision Sensor (DVS).\n",
    "\n",
    "2. A DVS camera is unique because it operates based on events, not frames like traditional cameras. This makes it tricky for standard methods to process its data.\n",
    "\n",
    "3. SNNs, on the other hand, are designed to process this kind of data. They work similarly to how our brain processes information, making them a good match for DVS cameras.\n",
    "\n",
    "4. The researchers designed a system that uses SNNs to process the data from the DVS camera. They also created a module that encodes the data into spikes, which the SNN can understand and process.\n",
    "\n",
    "5. They used a method called selective search to track objects by distinguishing between the target (what you want to track) and the background.\n",
    "\n",
    "6. The system they designed was very accurate, correctly classifying data 98.66% of the time in their tests.\n",
    "\n",
    "7. The tracking algorithm they developed can process over 1000 frames per second when it's optimized and run on a hardware simulator.\n",
    "\n",
    "8. This research is important because it shows how SNNs can be used with new hardware technologies to process data from DVS cameras efficiently and accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db757b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
